
\usepackage{etoolbox}
\usepackage{xkeyval}
\makeatletter

% These options can take values between 0 and 2.
% If 0, it is omitted.
% If 1, it is added to the list of heuristics.
% If 2, its definitions are also added.

% appending a delimited string to a variable, while using etoolbox list to remove duplicates.
% https://tex.stackexchange.com/questions/402173/append-strings-to-a-variable-and-display-them-at-the-front-of-the-document
\long\def\addto#1#2#3{%
  \ifinlist{#3}{#1}{%
  }{%
    \listadd{#1}{#3}%
    \ifdefempty#2{% first time, do not add comma
     \expandafter\def\expandafter#2\expandafter{#2#3}%
    }{%
     \expandafter\def\expandafter#2\expandafter{#2,#3}%
    }%
  }%
}%

\define@key{heuristics}{ff}[1]{%
 \def\heuristics@ff{#1}
 \ifnumcomp{\heuristics@ff}{>}{0}{%
  \addto{\heuristiclist}{\heuristicstr}{\ff}%
  \addto{\heuristiccitelist}{\heuristiccitestr}{hoffmann01}%
 }{}%
}
\define@key{heuristics}{ad}[1]{%
 \def\heuristics@ad{#1}
 \ifnumcomp{\heuristics@ad}{>}{0}{%
  \addto{\heuristiclist}{\heuristicstr}{\ad}%
  \addto{\heuristiccitelist}{\heuristiccitestr}{bonet2001planning}%
 }{}%
}
\define@key{heuristics}{hmax}[1]{%
 \def\heuristics@hmax{#1}
 \ifnumcomp{\heuristics@hmax}{>}{0}{%
  \addto{\heuristiclist}{\heuristicstr}{\hmax}%
  \addto{\heuristiccitelist}{\heuristiccitestr}{bonet2001planning}%
 }{}%
}
\define@key{heuristics}{gc}[1]{%
 \def\heuristics@gc{#1}
 \ifnumcomp{\heuristics@gc}{>}{0}{%
  \addto{\heuristiclist}{\heuristicstr}{\gc}%
  \addto{\heuristiccitelist}{\heuristiccitestr}{FikesHN72}%
 }{}%
}

\define@key{heuristics}{relaxation}[1]{\def\heuristics@relaxation{#1}}

\define@key{heuristics}{perfect}[1]{\ifnumcomp{\heuristics@properties}{<}{#1}{\def\heuristics@properties{#1}}{}}
\define@key{heuristics}{admissible}[2]{\ifnumcomp{\heuristics@properties}{<}{#1}{\def\heuristics@properties{#1}}{}}
\define@key{heuristics}{inadmissible}[3]{\ifnumcomp{\heuristics@properties}{<}{#1}{\def\heuristics@properties{#1}}{}}
\define@key{heuristics}{perfectsat}[4]{\ifnumcomp{\heuristics@properties}{<}{#1}{\def\heuristics@properties{#1}}{}}
\define@key{heuristics}{tdom}[5]{\ifnumcomp{\heuristics@properties}{<}{#1}{\def\heuristics@properties{#1}}{}}

\NewDocumentCommand{\heuristics}{O{}}{
\def\heuristics@ff{0}%
\def\heuristics@ad{0}%
\def\heuristics@hmax{0}%
\def\heuristics@gc{0}%
\def\heuristics@relaxation{0}%
\def\heuristics@properties{0}%
\def\heuristiclist{}
\def\heuristiccitelist{}
\def\heuristicstr{}
\def\heuristiccitestr{}
\setkeys{heuristics}{#1}%
%
Given a problem $\brackets{P,A,I,G}$ and a state $s$,
a domain-independent heuristic function $h(s, \brackets{P,A,I,G})$
returns an estimate of the cumulative cost from $s$ to one of the goal states (states that satisfy $G$),
typically through a symbolic, non-statistical means including problem relaxation and abstraction.
It is often abbreviated as $h(s)$ or $h(s,G)$.
\ifdefempty\heuristiclist{}{%
Notable \lsota functions that appear in this paper includes
$\heuristicstr$ \cite{\heuristiccitestr}.
}
\ifnumcomp{\heuristics@properties}{<}{1}{}{
  Often, the true optimal cost from a state $s$ is called
  the \emph{perfect heuristics} $h^*(s)$ \cite{helmert2008good}.
  \ifnumcomp{\heuristics@properties}{<}{2}{}{
    \emph{Admissible} heuristics are those which never overestimate $h^*$,
    i.e., $\forall s; h(s)\leq h^*(s)$.
    Optimizing algorithms like \astar \cite{hart1968formal} are
    guaranteed to find the optimal solutions with such heuristics.
    \ifnumcomp{\heuristics@properties}{<}{3}{}{
      Otherwise they are called \emph{inadmissible} heuristics,
      and are typically combined with satisficing/agile algorithms like GBFS \cite{doran1966experiments,bonet2001planning}.
      \ifnumcomp{\heuristics@properties}{<}{4}{}{
        Furthermore, heuristics that preserve the same ordering as $h^*$ are called
        \emph{perfect satisficing heuristics} \cite{kuroiwa2022biased},
        i.e., $\forall s,t; h(s)\leq h(t)\then h^*(s)\leq h^*(t)$.
        \ifnumcomp{\heuristics@properties}{<}{5}{}{
          Given a monotonic \emph{inflation} function $t:\R^{0+}\to\R^{0+}$
          s.t. $\forall x; t(x)\geq x$ and $\forall x,y; x\geq y \then t(x)\geq t(y)$,
          heuristics that preserve the same ordering as $h^*$ when inflated are called
          \emph{$t$-dominating heuristics},
          i.e., $\forall s,t; t(h(s))\leq h(t)\then h^*(s)\leq h^*(t)$.
        }
      }
    }
  }
}



\if\heuristics@relaxation1
A significant class of heuristics is called delete relaxation heuristics,
which solve a relaxed problem which does not contain delete effects,
and then returns the cost of the solution of the relaxed problem as an output.
The cost of the optimal solution of a delete relaxed planning problem from a state $s$ is
denoted by $h^+(s)$, but this is too expensive to compute in practice (NP-complete) \cite{bylander1996}.
Therefore, practical heuristics typically try to obtain its further relaxations
that can be computed in polynomial time.
\fi

\ifnumcomp{\heuristics@hmax}{>}{1}{
$\hmax$ \cite{bonet2001planning} is recursively defined as follows:
\begin{align}
 \hmax(s,G) = \max_{p\in G}
 \left\{
  \begin{array}{l}
   0\ \text{if}\ p\in s.\ \text{Otherwise,}\\
   \min_{\braces{a\in A\mid p\in\adde(a)}} \\
    \quad \left[\cost(a)+\ad(s, \pre(a))\right].
  \end{array}
 \right.
\end{align}
}{}

\ifnumcomp{\heuristics@ad}{>}{1}{
Additive heuristics $\ad$ \cite{bonet2001planning} is recursively defined as follows:
\begin{align}
 \ad(s,G) = \sum_{p\in G}
 \left\{
  \begin{array}{l}
   0\ \text{if}\ p\in s.\ \text{Otherwise,}\\
   \min_{\braces{a\in A\mid p\in\adde(a)}} \\
    \quad \left[\cost(a)+\ad(s, \pre(a))\right].
  \end{array}
 \right.
\end{align}
}{}

\ifnumcomp{\heuristics@ff}{>}{1}{
$\ff$ \cite{hoffmann01} is defined based on another heuristics $h$, such as $h=\ad$, as a subprocedure.
For each proposition $p$,
the action $a$ that adds $p$ with the minimal $\cost(a)+h(s, \pre(a))$
is conceptually ``the cheapest action that achieves a subgoal $p$'',
called the \emph{cheapest achiever} / \emph{best supporter} $\text{bs}(p,s,h)$ of $p$.
Using this, $\ff$ is defined as the sum of actions in a relaxed plan $\Pi^+$ constructed as follows:

\begin{align}
 \ff(s,G,h) &= \sum_{a\in \Pi^+(s,G,h)} \cost(a)\\
 \Pi^+(s,G,h) &= \bigcup_{p\in G}
 \left\{
  \begin{array}{l}
   \emptyset\ \text{if}\ p\in s.\ \text{Otherwise,}\\
   \braces{a} \cup \Pi^+(s,\pre(a)) \\
   \qquad \text{where}\ a=\text{bs}(p,s,h).
  \end{array}
 \right.\\
 \text{bs}(p,s,h)&=\argmin_{\braces{a\in A\mid p\in \adde(a)}} \left[\cost(a)+h(s, \pre(a))\right].
\end{align}
}{}

\ifnumcomp{\heuristics@gc}{>}{1}{
Goal Count heuristics $\gc$ is a simple heuristic proposed in \cite{FikesHN72}
that counts the number of propositions that are not satisfied yet.
$\brackets{\text{condition}}$ is a cronecker's delta / indicator function that returns 1 when the condition is satisfied.
\begin{align}
 \gc(s,G) &= \sum_{p\in G} \dbrackets{p\not \in s}.
\end{align}
}{}
}


\makeatother

% In this section, we discuss various approximations of delete-relaxed optimal cost $h^+(s)$.







